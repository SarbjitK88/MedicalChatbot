{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11341387,"sourceType":"datasetVersion","datasetId":7095586}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers datasets accelerate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install evaluate sentencepiece","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade accelerate\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install faiss-gpu\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer\nfrom datasets import load_dataset, DatasetDict\nimport torch\nimport numpy as np\nimport evaluate\nimport pandas as pd\nimport os\nimport faiss\nfrom datasets import Dataset\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.model_selection import train_test_split\nfrom transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:16:13.558964Z","iopub.execute_input":"2025-04-10T10:16:13.559391Z","iopub.status.idle":"2025-04-10T10:16:13.563994Z","shell.execute_reply.started":"2025-04-10T10:16:13.559370Z","shell.execute_reply":"2025-04-10T10:16:13.563002Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\n\ndata = pd.read_csv('/kaggle/input/medicaldata/finaldata.csv')\n\n# Handle missing values and ensure columns are strings\ndata['question'] = data['question'].fillna(\"\").astype(str)\ndata['answer'] = data['answer'].fillna(\"\").astype(str)\n\nquestions = data['question'].tolist() \nanswers = data['answer'].tolist()     ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:16:40.275375Z","iopub.execute_input":"2025-04-10T10:16:40.275702Z","iopub.status.idle":"2025-04-10T10:16:40.383906Z","shell.execute_reply.started":"2025-04-10T10:16:40.275677Z","shell.execute_reply":"2025-04-10T10:16:40.383159Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# RAG","metadata":{}},{"cell_type":"code","source":"model = SentenceTransformer('all-MiniLM-L6-v2')\n\nquestion_embeddings = model.encode(questions, convert_to_numpy=True)\n\ndimension = question_embeddings.shape[1]  \nindex = faiss.IndexFlatL2(dimension)      \nindex.add(question_embeddings)           ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:55:42.951837Z","iopub.execute_input":"2025-04-10T10:55:42.952149Z","iopub.status.idle":"2025-04-10T10:56:01.353218Z","shell.execute_reply.started":"2025-04-10T10:55:42.952126Z","shell.execute_reply":"2025-04-10T10:56:01.352538Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/319 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf0ee39acb674370a7684a23fe1d8e30"}},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"def interactive_query():\n    while True:\n        user_query = input(\"Enter your question (or 'exit' to quit): \")\n        if user_query.lower() == 'exit':\n            print(\"Exiting interactive session. Goodbye!\")\n            break\n        \n        query_embedding = model.encode([user_query], convert_to_numpy=True)\n        k = 1 \n        distances, indices = index.search(query_embedding, k)\n        \n        retrieved_answer = answers[indices[0][0]]\n        similarity_score = distances[0][0]\n        \n        print(\"\\n Answer: \", retrieved_answer)\n        print(f\"**Similarity Score:** {similarity_score:.4f}\\n\")\n\ninteractive_query()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:17:05.781211Z","iopub.execute_input":"2025-04-10T10:17:05.781514Z","iopub.status.idle":"2025-04-10T10:17:38.768757Z","shell.execute_reply.started":"2025-04-10T10:17:05.781492Z","shell.execute_reply":"2025-04-10T10:17:38.767996Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter your question (or 'exit' to quit):  A 62-year-old woman presents to her physician with a painless breast mass on her left breast for the past 4 months. She mentions that she noticed the swelling suddenly one day and thought it would resolve by itself. Instead, it has been slowly increasing in size. On physical examination of the breasts, the physician notes a single non-tender, hard, and fixed nodule over left breast. An ultrasonogram of the breast shows a solid mass, and a fine-needle aspiration biopsy confirms the mass to be lobular carcinoma of the breast. When the patient asks about her prognosis, the physician says that the prognosis can be best determined after both grading and staging of the tumor. Based on the current diagnostic information, the physician says that they can only grade, but no stage, the neoplasm. Which of the following facts about the neoplasm is currently available to the physician?\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f0a1536c74a4f57a7adbcbc58b93789"}},"metadata":{}},{"name":"stdout","text":"\n Answer:  The tumor cells exhibit marked nuclear atypia.\n**Similarity Score:** 0.0000\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your question (or 'exit' to quit):  A 47-year-old female with a history of hypertension presents to your outpatient clinic for numbness, tingling in her right hand that has been slowly worsening over the last several months. She has tried using a splint but receives minimal relief. She is an analyst for a large consulting firm and spends most of her workday in front of a computer. Upon examination, you noticed that the patient has a prominent jaw and her hands appear disproportionately large. Her temperature is 99 deg F (37.2 deg C), blood pressure is 154/72 mmHg, pulse is 87/min, respirations are 12/min. A fasting basic metabolic panel shows: Na: 138 mEq/L, K: 4.1 mEq/L, Cl: 103 mEq/L, CO2: 24 mEq/L, BUN: 12 mg/dL, Cr: 0.8 mg/dL, Glucose: 163 mg/dL. Which of the following tests would be most helpful in identifying the underlying diagnosis?\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81c6476a1668406aba89810ecefc90b3"}},"metadata":{}},{"name":"stdout","text":"\n Answer:  Measurement of insulin-like growth factor 1 alone and growth hormone levels after oral glucose\n**Similarity Score:** 0.0000\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your question (or 'exit' to quit):  exit\n"},{"name":"stdout","text":"Exiting interactive session. Goodbye!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Fine Tune LLM","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, data, tokenizer, max_len=128):\n        self.questions = data['question']\n        self.answers = data['answer']\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.questions)\n\n    def __getitem__(self, idx):\n        question = self.questions[idx]\n        answer = self.answers[idx]\n        inputs = self.tokenizer(\n            question, max_length=self.max_len, truncation=True, padding=\"max_length\", return_tensors=\"pt\"\n        )\n        targets = self.tokenizer(\n            answer, max_length=self.max_len, truncation=True, padding=\"max_length\", return_tensors=\"pt\"\n        )\n        return {\n            \"input_ids\": inputs[\"input_ids\"].squeeze(),\n            \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n            \"labels\": targets[\"input_ids\"].squeeze(),\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:17:45.477987Z","iopub.execute_input":"2025-04-10T10:17:45.478280Z","iopub.status.idle":"2025-04-10T10:17:45.484232Z","shell.execute_reply.started":"2025-04-10T10:17:45.478256Z","shell.execute_reply":"2025-04-10T10:17:45.483495Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/medicaldata/finaldata.csv')\ntrain_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n\ntrain_data.to_csv(\"train_data.csv\", index=False)\ntest_data.to_csv(\"test_data.csv\", index=False)\nprint(\"Train/Test split done!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:17:56.361000Z","iopub.execute_input":"2025-04-10T10:17:56.361421Z","iopub.status.idle":"2025-04-10T10:17:56.666625Z","shell.execute_reply.started":"2025-04-10T10:17:56.361381Z","shell.execute_reply":"2025-04-10T10:17:56.665710Z"}},"outputs":[{"name":"stdout","text":"Train/Test split done!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\nmodel = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:17:58.993159Z","iopub.execute_input":"2025-04-10T10:17:58.993482Z","iopub.status.idle":"2025-04-10T10:18:00.081526Z","shell.execute_reply.started":"2025-04-10T10:17:58.993454Z","shell.execute_reply":"2025-04-10T10:18:00.080628Z"}},"outputs":[{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"train_data_path = \"train_data.csv\"\ntest_data_path = \"test_data.csv\"\ntrain_data = pd.read_csv(train_data_path)\ntest_data = pd.read_csv(test_data_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:18:02.462633Z","iopub.execute_input":"2025-04-10T10:18:02.463013Z","iopub.status.idle":"2025-04-10T10:18:02.558803Z","shell.execute_reply.started":"2025-04-10T10:18:02.462987Z","shell.execute_reply":"2025-04-10T10:18:02.558034Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_data = train_data[train_data['answer'].map(type) == str]\ntest_data = test_data[test_data['answer'].map(type) == str]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:18:05.516292Z","iopub.execute_input":"2025-04-10T10:18:05.516588Z","iopub.status.idle":"2025-04-10T10:18:05.525597Z","shell.execute_reply.started":"2025-04-10T10:18:05.516557Z","shell.execute_reply":"2025-04-10T10:18:05.524614Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_data = train_data.reset_index(drop=True)\n\ntest_data = test_data.reset_index(drop=True)\n\nprint(\"Index reset successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:18:08.225260Z","iopub.execute_input":"2025-04-10T10:18:08.225544Z","iopub.status.idle":"2025-04-10T10:18:08.231614Z","shell.execute_reply.started":"2025-04-10T10:18:08.225523Z","shell.execute_reply":"2025-04-10T10:18:08.230676Z"}},"outputs":[{"name":"stdout","text":"Index reset successfully!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"print(train_data.index) \nprint(test_data.index)  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:18:11.592236Z","iopub.execute_input":"2025-04-10T10:18:11.592522Z","iopub.status.idle":"2025-04-10T10:18:11.597669Z","shell.execute_reply.started":"2025-04-10T10:18:11.592500Z","shell.execute_reply":"2025-04-10T10:18:11.596723Z"}},"outputs":[{"name":"stdout","text":"RangeIndex(start=0, stop=8141, step=1)\nRangeIndex(start=0, stop=2036, step=1)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"train_dataset = CustomDataset(train_data, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:18:17.360273Z","iopub.execute_input":"2025-04-10T10:18:17.360566Z","iopub.status.idle":"2025-04-10T10:18:17.364391Z","shell.execute_reply.started":"2025-04-10T10:18:17.360544Z","shell.execute_reply":"2025-04-10T10:18:17.363692Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./flan_t5_base_results\",\n    run_name=\"flan_t5_medical_query_finetuning\",\n    learning_rate=3e-5,\n    per_device_train_batch_size=8,\n    num_train_epochs=3,\n    save_steps=500,\n    logging_steps=100,\n    save_total_limit=1,\n    fp16=True, \n    eval_strategy=\"no\",\n    no_cuda=False,\n    report_to=\"none\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:18:19.748814Z","iopub.execute_input":"2025-04-10T10:18:19.749125Z","iopub.status.idle":"2025-04-10T10:18:19.783273Z","shell.execute_reply.started":"2025-04-10T10:18:19.749101Z","shell.execute_reply":"2025-04-10T10:18:19.782634Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:18:22.807136Z","iopub.execute_input":"2025-04-10T10:18:22.807427Z","iopub.status.idle":"2025-04-10T10:18:23.171343Z","shell.execute_reply.started":"2025-04-10T10:18:22.807405Z","shell.execute_reply":"2025-04-10T10:18:23.170403Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# torch.cuda.empty_cache()\n# torch.cuda.ipc_collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:18:26.407944Z","iopub.execute_input":"2025-04-10T10:18:26.408339Z","iopub.status.idle":"2025-04-10T10:39:20.083030Z","shell.execute_reply.started":"2025-04-10T10:18:26.408308Z","shell.execute_reply":"2025-04-10T10:39:20.082071Z"}},"outputs":[{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1527' max='1527' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1527/1527 20:51, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>12.985400</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.267300</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.293800</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.255800</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.251300</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.240000</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.239800</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.235600</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.226300</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.237800</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.231300</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.222000</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.227300</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.228000</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.230900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1527, training_loss=1.141709942870774, metrics={'train_runtime': 1253.3486, 'train_samples_per_second': 19.486, 'train_steps_per_second': 1.218, 'total_flos': 4180957204709376.0, 'train_loss': 1.141709942870774, 'epoch': 3.0})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"test_dataset = CustomDataset(test_data, tokenizer)\n\nresults = trainer.evaluate(eval_dataset=test_dataset)\nprint(\"Evaluation Results:\", results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:39:27.674386Z","iopub.execute_input":"2025-04-10T10:39:27.674733Z","iopub.status.idle":"2025-04-10T10:40:07.374936Z","shell.execute_reply.started":"2025-04-10T10:39:27.674700Z","shell.execute_reply":"2025-04-10T10:40:07.374171Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='128' max='128' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [128/128 00:39]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 0.20866546034812927, 'eval_runtime': 39.6938, 'eval_samples_per_second': 51.293, 'eval_steps_per_second': 3.225, 'epoch': 3.0}\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"model.save_pretrained(\"./fine_tuned_flan_t5_base\")\ntokenizer.save_pretrained(\"./fine_tuned_flan_t5_base\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:40:14.838141Z","iopub.execute_input":"2025-04-10T10:40:14.838434Z","iopub.status.idle":"2025-04-10T10:40:17.302116Z","shell.execute_reply.started":"2025-04-10T10:40:14.838412Z","shell.execute_reply":"2025-04-10T10:40:17.301185Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"('./fine_tuned_flan_t5_base/tokenizer_config.json',\n './fine_tuned_flan_t5_base/special_tokens_map.json',\n './fine_tuned_flan_t5_base/spiece.model',\n './fine_tuned_flan_t5_base/added_tokens.json')"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"import shutil\n\nmodel_folder = \"./fine_tuned_flan_t5_base\"\n\nzip_file = \"flan_t5_fine_tuned.zip\"\nshutil.make_archive(base_name=\"flan_t5_fine_tuned\", format=\"zip\", root_dir=model_folder)\n\nprint(f\"Model saved successfully as {zip_file}.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:40:25.834897Z","iopub.execute_input":"2025-04-10T10:40:25.835225Z","iopub.status.idle":"2025-04-10T10:41:14.419299Z","shell.execute_reply.started":"2025-04-10T10:40:25.835197Z","shell.execute_reply":"2025-04-10T10:41:14.418382Z"}},"outputs":[{"name":"stdout","text":"Model saved successfully as flan_t5_fine_tuned.zip.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# from IPython.display import FileLink\n\n# # Provide a download link\n# FileLink(zip_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T10:41:18.496922Z","iopub.execute_input":"2025-04-10T10:41:18.497211Z","iopub.status.idle":"2025-04-10T10:41:18.502158Z","shell.execute_reply.started":"2025-04-10T10:41:18.497190Z","shell.execute_reply":"2025-04-10T10:41:18.501350Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/flan_t5_fine_tuned.zip","text/html":"<a href='flan_t5_fine_tuned.zip' target='_blank'>flan_t5_fine_tuned.zip</a><br>"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"# **Fallback**","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nimport faiss\n\nretrieval_model = SentenceTransformer('all-MiniLM-L6-v2')\nfallback_model = T5ForConditionalGeneration.from_pretrained(\"./fine_tuned_flan_t5_base\")\nfallback_tokenizer = T5Tokenizer.from_pretrained(\"./fine_tuned_flan_t5_base\")\n\nquestions = data['question'].tolist()  # Use unmodified data for retrieval\nanswers = data['answer'].tolist()\n\nquestion_embeddings = retrieval_model.encode(questions, convert_to_numpy=True)\ndimension = question_embeddings.shape[1]\nindex = faiss.IndexFlatL2(dimension)\nindex.add(question_embeddings)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_fallback_answer(query):\n    inputs = fallback_tokenizer(\n        query, return_tensors=\"pt\", max_length=128, truncation=True, padding=\"max_length\"\n    )\n    outputs = fallback_model.generate(\n        inputs[\"input_ids\"], max_length=50, num_beams=5, early_stopping=True\n    )\n    return fallback_tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nthreshold = 0.5  # Define threshold based on testing\n\ndef query_pipeline(user_query):\n    # Step 1: Retrieve using FAISS\n    query_embedding = retrieval_model.encode([user_query], convert_to_numpy=True)\n    k = 1\n    distances, indices = index.search(query_embedding, k)\n    distance = distances[0][0]  # L2 distance\n    retrieved_answer = answers[indices[0][0]]\n\n    # Calculate query length\n    query_length = len(user_query.split())\n    print(f\"Query Length: {query_length}\")\n\n    # Step 2: Apply enhanced fallback logic\n    threshold = 0.8  # Distance threshold\n    if (distance > threshold ):\n        print(\"Fallback triggered! Generating answer...\")\n        return generate_fallback_answer(user_query)\n    else:\n        return retrieved_answer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T11:57:59.988098Z","iopub.execute_input":"2025-04-10T11:57:59.988419Z","iopub.status.idle":"2025-04-10T11:57:59.995693Z","shell.execute_reply.started":"2025-04-10T11:57:59.988390Z","shell.execute_reply":"2025-04-10T11:57:59.994524Z"}},"outputs":[],"execution_count":54},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"def interactive_test():\n    print(\"Interactive Doctor GPT Chatbot\")\n    print(\"Type 'exit' to quit.\\n\")\n    while True:\n        user_query = input(\"Enter your question: \")\n        if user_query.lower() == 'exit':\n            print(\"Exiting interactive session. Goodbye!\")\n            break\n        response = query_pipeline(user_query)\n        print(\"\\n**Response:**\", response, \"\\n\")\n\n# Run the interactive session\ninteractive_test()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T11:55:13.864032Z","iopub.execute_input":"2025-04-10T11:55:13.864329Z","iopub.status.idle":"2025-04-10T11:57:54.166803Z","shell.execute_reply.started":"2025-04-10T11:55:13.864304Z","shell.execute_reply":"2025-04-10T11:57:54.165972Z"}},"outputs":[{"name":"stdout","text":"Interactive Doctor GPT Chatbot\nType 'exit' to quit.\n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your question:  A 67-year-old man comes to the physician because of a 3-day history of fever, chills, headache, and fatigue. He appears ill. His temperature is 39°C (102.2°F). Analysis of nasal secretions shows infection with an enveloped, single-stranded segmented RNA virus. In response to infection with this pathogen, certain cells present antigens from the pathogen to CD8+ T-lymphocytes. Which of the following statements about the molecules used for the presentation of these antigens is most accurate?\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2161ad08fa5e4443b6871776013ec5c9"}},"metadata":{}},{"name":"stdout","text":"Query Length: 74\nAverage Question Length: 116.18\n\n**Response:** The molecule consists of a heavy chain associated with β2 microglobulin \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your question:  A 7-year-old boy comes to the physician because of a generalized rash for 3 days. Over the past 5 days, he has also had a high fever and a sore throat. His 16-year-old sister was treated for infectious mononucleosis 2 weeks ago. He returned from a summer camp a week ago. His immunizations are up-to-date. Three years ago, he required intubation after an allergic reaction to dicloxacillin. The patient appears ill. His temperature is 38.2°C (100.8°F). Examination shows circumferential oral pallor. Cervical lymphadenopathy is present. There is tonsillar erythema and exudate. A confluent, blanching, punctate erythematous rash with a rough texture is spread over his trunk and extremities. His hemoglobin concentration is 13.3 g/dL, leukocyte count is 12,000/mm3, and erythrocyte sedimentation rate is 43 mm/h. Which of the following is the most appropriate next step in management?\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"204b74ca8c564a6a8f69dd0bb6d095ed"}},"metadata":{}},{"name":"stdout","text":"Query Length: 137\nAverage Question Length: 116.18\n\n**Response:** Azithromycin therapy \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your question:  A 45-year-old man presents with epigastric pain that improves after eating but returns a few hours later. He has a history of regular nonsteroidal anti-inflammatory drug (NSAID) use. Is it the most likely the ulcer disease?\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64b5a8d8be3f4d71b045321573c34245"}},"metadata":{}},{"name":"stdout","text":"Query Length: 36\nAverage Question Length: 116.18\n\n**Response:** Gastroduodenal artery \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your question:  A 45-year-old man presents with epigastric pain that improves after eating but returns a few hours later. He has a history of regular nonsteroidal anti-inflammatory drug (NSAID) use. Is it peptic ulcer disease?\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdeff93bba6d43e2a466b4323a112b5c"}},"metadata":{}},{"name":"stdout","text":"Query Length: 33\nAverage Question Length: 116.18\n\n**Response:** Epithelium, lamina propria, muscularis mucosa, and submucosa \n\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter your question:  exit\n"},{"name":"stdout","text":"Exiting interactive session. Goodbye!\n","output_type":"stream"}],"execution_count":53},{"cell_type":"markdown","source":"# Streamlit app code","metadata":{}},{"cell_type":"code","source":"!pip install streamlit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:08:17.792849Z","iopub.execute_input":"2025-04-10T12:08:17.793141Z","iopub.status.idle":"2025-04-10T12:08:23.038775Z","shell.execute_reply.started":"2025-04-10T12:08:17.793119Z","shell.execute_reply":"2025-04-10T12:08:23.037591Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting streamlit\n  Downloading streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\nRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\nRequirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\nRequirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\nRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\nRequirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\nRequirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\nRequirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.3)\nRequirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\nRequirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\nRequirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (19.0.1)\nRequirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\nRequirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\nRequirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\nRequirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\nRequirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.0.0)\nRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\nCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\nRequirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\nRequirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (1.18.4)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.23->streamlit) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.23->streamlit) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.23->streamlit) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.23->streamlit) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.23->streamlit) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3,>=1.23->streamlit) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3,>=1.23->streamlit) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3,>=1.23->streamlit) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.23->streamlit) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3,>=1.23->streamlit) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3,>=1.23->streamlit) (2024.2.0)\nDownloading streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pydeck, streamlit\nSuccessfully installed pydeck-0.9.1 streamlit-1.44.1\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"import subprocess","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:19:56.008139Z","iopub.execute_input":"2025-04-10T12:19:56.008431Z","iopub.status.idle":"2025-04-10T12:19:56.012392Z","shell.execute_reply.started":"2025-04-10T12:19:56.008408Z","shell.execute_reply":"2025-04-10T12:19:56.011455Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"streamlit_code = \"\"\"\nimport streamlit as st\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\nimport faiss\nimport pandas as pd\n\n# Load pre-trained models and data\nretrieval_model = SentenceTransformer('all-MiniLM-L6-v2')\nfallback_model = T5ForConditionalGeneration.from_pretrained(\"./fine_tuned_flan_t5_base\")\nfallback_tokenizer = T5Tokenizer.from_pretrained(\"./fine_tuned_flan_t5_base\")\n\n# Load FAISS index\nindex = faiss.read_index(\"/kaggle/working/faiss_index.index\")\n\n# Load dataset questions and answers\ndata = pd.read_csv('/kaggle/input/medicaldata/finaldata.csv')\nquestions = data['question'].tolist()\nanswers = data['answer'].tolist()\n\n# Fallback function\ndef generate_fallback_answer(query):\n    inputs = fallback_tokenizer(\n        query, return_tensors=\"pt\", max_length=128, truncation=True, padding=\"max_length\"\n    )\n    outputs = fallback_model.generate(\n        inputs[\"input_ids\"], max_length=50, num_beams=5, early_stopping=True\n    )\n    return fallback_tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n# Query pipeline\nthreshold = 0.8\ndef query_pipeline(user_query):\n    query_embedding = retrieval_model.encode([user_query], convert_to_numpy=True)\n    k = 1\n    distances, indices = index.search(query_embedding, k)\n    distance = distances[0][0]\n    retrieved_answer = answers[indices[0][0]]\n\n    if distance > threshold:\n        return generate_fallback_answer(user_query)\n    else:\n        return retrieved_answer\n\n# Streamlit app\ndef main():\n    st.title(\"Doctor GPT 🩺\")\n    st.write(\"Ask any medical query and let the chatbot assist you!\")\n\n    # User input\n    user_query = st.text_input(\"Enter your medical question:\")\n\n    if st.button(\"Get Answer\"):\n        if user_query:\n            response = query_pipeline(user_query)\n            st.success(f\"**Response:** {response}\")\n        else:\n            st.error(\"Please enter a question!\")\n\nif __name__ == \"__main__\":\n    main()\n\"\"\"\n\n# Save code to a Python script\nwith open(\"chatbot_app.py\", \"w\") as f:\n    f.write(streamlit_code)\nprint(\"Streamlit code saved as chatbot_app.py!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:46:31.585621Z","iopub.execute_input":"2025-04-10T12:46:31.586049Z","iopub.status.idle":"2025-04-10T12:46:31.592899Z","shell.execute_reply.started":"2025-04-10T12:46:31.586020Z","shell.execute_reply":"2025-04-10T12:46:31.591907Z"}},"outputs":[{"name":"stdout","text":"Streamlit code saved as chatbot_app.py!\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"!pip install pyngrok","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:30:22.652370Z","iopub.execute_input":"2025-04-10T12:30:22.652713Z","iopub.status.idle":"2025-04-10T12:30:26.253341Z","shell.execute_reply.started":"2025-04-10T12:30:22.652682Z","shell.execute_reply":"2025-04-10T12:30:26.252439Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting pyngrok\n  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\nDownloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\nInstalling collected packages: pyngrok\nSuccessfully installed pyngrok-7.2.3\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"!ngrok config add-authtoken 2vXPJtqghyvoldzhiCLevVZd9rF_5zG4YqqH4mqvgaXjj1qXt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T12:35:17.447597Z","iopub.execute_input":"2025-04-10T12:35:17.447965Z","iopub.status.idle":"2025-04-10T12:35:17.773278Z","shell.execute_reply.started":"2025-04-10T12:35:17.447941Z","shell.execute_reply":"2025-04-10T12:35:17.771925Z"}},"outputs":[{"name":"stdout","text":"Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"from pyngrok import ngrok\nimport subprocess\n\n# Start Streamlit in the background\nstreamlit_process = subprocess.Popen([\"streamlit\", \"run\", \"chatbot_app.py\"])\n\n# Open an Ngrok tunnel for port 8502\npublic_url = ngrok.connect(8502)\nprint(\"Public URL:\", public_url)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T14:19:43.512340Z","iopub.execute_input":"2025-04-10T14:19:43.512733Z","iopub.status.idle":"2025-04-10T14:19:43.613078Z","shell.execute_reply.started":"2025-04-10T14:19:43.512701Z","shell.execute_reply":"2025-04-10T14:19:43.611552Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout, auth)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0mresponse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: HTTP Error 502: Bad Gateway","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-75-ea6bba768b9d>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Open an Ngrok tunnel for port 8502\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8502\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Public URL:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublic_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     tunnel = NgrokTunnel(api_request(f\"{api_url}/api/tunnels\", method=\"POST\", data=options,\n\u001b[0m\u001b[1;32m    356\u001b[0m                                      timeout=pyngrok_config.request_timeout),\n\u001b[1;32m    357\u001b[0m                          pyngrok_config, api_url)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(url, method, data, params, timeout, auth)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Response {status_code}: {response_data.strip()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         raise PyngrokNgrokHTTPError(f\"ngrok client exception, API returned {status_code}: {response_data}\",\n\u001b[0m\u001b[1;32m    579\u001b[0m                                     \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                                     status_code, e.reason, e.headers, response_data)\n","\u001b[0;31mPyngrokNgrokHTTPError\u001b[0m: ngrok client exception, API returned 502: {\"error_code\":103,\"status_code\":502,\"msg\":\"failed to start tunnel\",\"details\":{\"err\":\"failed to start tunnel: Your account may not run more than 3 tunnels over a single ngrok agent session.\\nThe tunnels already running on this session are:\\ntn_2vXPfme1ewckPRcaA7fhMShpmhe, tn_2vXR24tInYajrP9vHidDAo8NP94, tn_2vXXkxERzs2cseBNewIDFpoFCXj\\n\\r\\n\\r\\nERR_NGROK_324\\r\\n\"}}\n"],"ename":"PyngrokNgrokHTTPError","evalue":"ngrok client exception, API returned 502: {\"error_code\":103,\"status_code\":502,\"msg\":\"failed to start tunnel\",\"details\":{\"err\":\"failed to start tunnel: Your account may not run more than 3 tunnels over a single ngrok agent session.\\nThe tunnels already running on this session are:\\ntn_2vXPfme1ewckPRcaA7fhMShpmhe, tn_2vXR24tInYajrP9vHidDAo8NP94, tn_2vXXkxERzs2cseBNewIDFpoFCXj\\n\\r\\n\\r\\nERR_NGROK_324\\r\\n\"}}\n","output_type":"error"}],"execution_count":75}]}